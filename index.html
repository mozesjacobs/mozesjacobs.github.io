<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Mozes Jacobs</title>
  <meta name="author" content="Mozes Jacobs">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Mozes Jacobs</name>
                  </p>
                  <p>
                    I am a third-year computer science PhD candidate at Harvard University, advised by Professor <a
                      href="http://www.demba-ba.org">Demba Ba</a>. I am supported by the <a
                      href="https://www.harvard.edu/kempner-institute/opportunities/the-kempner-institute-graduate-fellowship/">Kempner
                      Institute Graduate Fellowship</a>.
                  </p>
                  <p>
                    I'm interested in <strong>Visual Representation Learning</strong> and
                    <strong>Interpretability</strong>.
                  </p>
                  <p>
                    My work investigates how large-scale vision models transform high-dimensional visual inputs into
                    structured semantic representations. I am interested in training vision foundation models and
                    understanding them through mechanistic interpretability approaches that reveal the computational
                    principles underlying machine vision. I am curious about how we can leverage these insights to
                    engineer architectural inductive biases that enhance model efficiency, robustness, and
                    generalization while remaining compatible with large-scale training. Recently, I have been exploring
                    dynamical interpretability—analyzing how representations evolve as trajectories through activation
                    space—to uncover convergence dynamics, token-specific behaviors, and low-dimensional geometric
                    structure that governs how vision models process information.
                  </p>
                  <p>
                    Previously, I worked at the <a href="https://dynamicsai.org">AI Institute in Dynamic Systems</a>
                    with <a href="https://amath.washington.edu/people/j-nathan-kutz">Nathan Kutz</a> and <a
                      href="https://ryraut.github.io">Ryan Raut</a>. I earned my B.S. in computer science from the <a
                      href="https://www.cs.washington.edu">Allen School</a> at the <a
                      href="https://www.washington.edu">University of Washington</a>, where I worked with <a
                      href="https://www.rajeshpnrao.com">Rajesh Rao</a> and <a
                      href="https://noble.gs.washington.edu/~wnoble/">William Noble</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:mozesjacobs@g.harvard.edu">Email</a> &nbsp/&nbsp
                    <a href="Resume.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.co.uk/citations?user=8Dm0KfQAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://x.com/mozesjacobs">Twitter</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/mozesjacobs/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="mozes3.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="mozes3.jpg"
                      class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Publications</heading>
                  <p>* denotes equal contribution</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- Paper 1: Block-Recurrent Dynamics -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="raptor.png" alt="raptor" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2512.19941">
                    <papertitle>Block-Recurrent Dynamics in ViTs</papertitle>
                  </a>
                  <br>
                  <strong>Mozes Jacobs*</strong>,
                  Thomas Fel*,
                  Richard Hakim*,
                  Alessandra Brondetta,
                  Demba Ba,
                  T. Andy Keller
                  <br>
                  <em>Accepted to ICLR</em>, 2026
                  <br>
                  <p>
                    We introduce the Block-Recurrent Hypothesis (BRH), arguing that trained ViTs admit a block-recurrent
                    depth structure. To validate this, we train recurrent surrogates called Raptor. We demonstrate that
                    a Raptor model can recover <strong>96% of DINOv2 ImageNet-1k linear probe accuracy in only 2
                      blocks</strong> while maintaining equivalent runtime. We leverage our hypothesis to
                    perform dynamical interpretability, revealing directional convergence into class-dependent basins,
                    token-specific trajectory dynamics, and low-rank attractor structure in late layers.
                  </p>
                </td>
              </tr>

              <!-- Paper 2: Traveling Waves (CCN) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="traveling_waves.gif" alt="traveling_waves" width="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/pdf?id=QEzqo546V5">
                    <papertitle>Traveling Waves Integrate Spatial Information Through Time</papertitle>
                  </a>
                  <br>
                  <strong>Mozes Jacobs</strong>,
                  Robert C. Budzinski,
                  Lyle Muller,
                  Demba Ba,
                  T. Andy Keller
                  <br>
                  <em>CCN (Oral)</em>, 2025
                  <br>
                  <a
                    href="https://kempnerinstitute.harvard.edu/research/deeper-learning/traveling-waves-integrate-spatial-information-through-time/">blog</a>
                  /
                  <a href="https://youtu.be/ePNrhdT9cqQ?si=xFrdlLSSUaLa6oYl&t=588">talk</a>
                  <p>
                    We investigate how traveling waves of neural activity enable spatial information integration in
                    convolutional recurrent networks. Our models learn to generate traveling waves in response to visual
                    stimuli, effectively expanding receptive fields of locally connected neurons. This mechanism
                    significantly outperforms local feed-forward networks on semantic segmentation tasks requiring
                    global spatial context, achieving comparable performance to non-local U-Nets while using
                    significantly fewer parameters.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Other Work</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- Paper 3: Traveling Waves (Workshop) -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2502.06034">
                    <papertitle>Traveling Waves Integrate Spatial Information Into Spectral Representations</papertitle>
                  </a>
                  <br>
                  <strong>Mozes Jacobs</strong>,
                  Robert C. Budzinski,
                  Lyle Muller,
                  Demba Ba,
                  T. Andy Keller
                  <br>
                  <em>ICLR 2025 Re-Align Workshop</em>
                </td>
              </tr>

              <!-- Paper 4: HyperSINDY -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2310.04832">
                    <papertitle>HyperSINDY: Deep Generative Modeling of Nonlinear Stochastic Governing Equations
                    </papertitle>
                  </a>
                  <br>
                  <strong>Mozes Jacobs</strong>,
                  Bingni W. Brunton,
                  Steven L. Brunton,
                  J. Nathan Kutz,
                  Ryan V. Raut
                  <br>
                  <em>arXiv</em>, 2023
                </td>
              </tr>

              <!-- Paper 5: GOPC -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://mozesjacobs.github.io/gopc.pdf">
                    <papertitle>Gradient Origin Predictive Coding</papertitle>
                  </a>
                  <br>
                  <strong>Mozes Jacobs</strong>,
                  Linxing Preston Jiang,
                  Rajesh N.P. Rao
                  <br>
                  <em>Undergraduate senior thesis</em>, 2022
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Website template from <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>